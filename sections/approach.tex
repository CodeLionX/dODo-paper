% !TeX root = ../paper.tex
% !TeX encoding = UTF-8
% !TeX spellcheck = en_US

\section{Distributed discovery of \glspl{od}}\label{sec:approach}

  We now present our approach to \gls{od} discovery, called \dodo{}.
  First, we explain how \ocddiscover{}~\cite{consonni} traverses the candidate space to find minimal \glspl{ocd} and \glspl{od} in \cref{sec:ocddiscover}.
  This is the algorithmic foundation of our approach, which we slightly adopt to be able to distribute the discovery across several nodes in a cluster (see \cref{sec:dodo}).
  \Cref{sec:architecture} then describes \dodo{}'s architecture and \cref{sec:protocols} the communication protocols used to make a \dodo{} cluster fault-tolerant and elastic.
 
\subsection{The \ocddiscover{} algorithm}\label{sec:ocddiscover}

  The \ocddiscover{} algorithm creates the search space to find \glspl{od} over \glspl{ocd}~\cite{consonni}.
  This reduces the number of candidates that the algorithm must check, because \glspl{ocd} are symmetrical.
  \Citeauthor{consonni} prove that if a \gls{od} holds, than a functional dependency and a \gls{ocd} hold as well.
  Based on this theorem, they then use a breadth-first search strategy to identify \gls{ocd} relations in the dataset to discover minimal dependencies before longer ones.

  The \ocddiscover{} algorithm consists of two phases.
  In the first phase, \ocddiscover{} performs an initial pruning step that removes constant columns and reduces order equivalent columns of the original column set.
  The constant columns and order equivalent columns are part of the output.
  They would generate a huge amount of \glspl{od} and those \glspl{od} can easily reconstructed from the result later on.

  In the second phase, the actual \gls{od} discovery takes place.
  \ocddiscover{} generates \gls{ocd} candidates from the remaining columns in levels, one after the other.
  For each level the algorithm checks if the \gls{ocd} candidates hold.
  If a candidate holds, the candidate is further checked for being order dependent, the results are emitted, and child \gls{ocd} candidates are generated.
  This step includes further pruning rules~\cite{consonni}.
  If the \gls{ocd} candidate does not hold, no new candidates starting from it are generated.
  All newly generated candidates are then put into a list for the next level.

  \Citeauthor{consonni} proved in their paper, that they would be able to find all minimal \glspl{od}.
  However, as \citeauthor{szlichta:errata} showed in their Errata Note, \citeauthor{consonni} made a mistake in one of their proofs and this method of building the search space does not create minimal \glspl{od} with repeated prefixes~\cite{szlichta:errata}.

\subsection{The \dodo{} algorithm}\label{sec:dodo}

  We use \citeauthor{consonni}'s work as the basis of our discovery algorithm.
  Conceptually, \dodo{} works the same as \ocddiscover{}.
  This means that we also perform a breadth-first search in a \gls{ocd} candidate tree and our algorithm also consists of an initial pruning step followed by the actual search step.
  However, our implementation of the algorithm differs.

  Instead of generating our candidates level-wise, we use a task-based approach with a single task queue.
  We initiate the task queue with the initial \gls{ocd} candidates comparable to the first level generation by \citeauthor{consonni}.
  Each task's input is the \gls{ocd} candidate.
  Its outputs are the results from checking the candidate and a set of new tasks that can be empty.
  The results are emitted as output and the new tasks (child candidates) are added to the task queue.
  This is possible, because \gls{ocd} candidate checking and the generation of new candidates is independent from the other candidates~\cite{consonni}.
  This setup allows us to parallelize the processing, because the tasks in the task queue can be processed independently and concurrently.
  To distribute our algorithm, we just spread the tasks, ideally evenly, across our cluster.

\subsection{Implementation of the \dodo{} algorithm}\label{sec:architecture}

  We implement the \dodo{} algorithm using Akka~\cite{akka}, Akka Clustering~\cite{akka:clustering} and the Scala programming language~\cite{scala}.
  Akka is a toolkit for building distributed message-driven applications using the actor programming model that was first introduced in Orleans~\cite{bernstein:orleans}.
  It provides tools for concurrency, distribution, and elasticity.

  The \dodo{} algorithm is designed as a peer-to-peer cluster.
  All nodes in the cluster are equal and employ the same internal architecture.
  The nodes are arranged on a ring, so that every node has two neighbors.
  Based on this cluster layout, we define communication protocols (see \cref{sec:protocols}) to balance the workload, to recover from node failures, and to allow dynamic cluster sizes.
  Each node runs its own actor system with the complete set of \dodo{} actors (\cref{sec:node-architecture} describes them in more detail) and works on the checking of \glspl{ocd} and the generation of new \gls{ocd} candidates.
  \Cref{fig:dodo-architecture} shows the cluster architecture and the internal architecture of the nodes' actor systems exemplarily by node two.

  \begin{figure}
    \centering
    \input{pictures/tikz/dodo-architecture}
    \caption{DODO architecture}
    \label{fig:dodo-architecture}
  \end{figure}

  The execution of the \dodo{} algorithm in the cluster is initiated by a seed node.
  The seed node plays a special role in our cluster and it is the only exception to the peer-to-peer approach.
  It is started before all other nodes and has the following unique tasks:

  \begin{itemize}
    \item The seed node is the initial contact point for all nodes that want to join the cluster.
    \item It always loads the dataset from disk into memory.
    \item It performs the initial pruning and generates the first \gls{ocd} candidates.
  \end{itemize}

  The seed node is the first node in the cluster and may be the only one in the cluster for some time.
  If the seed node fails during this first phase, the whole cluster shuts down and must be restarted.
  We do not implement resilience for this first phase.
  This seemed to be a reasonable constraint, though, because the first phase only takes a few seconds.

  After the seed node started up, it immediately starts with the discovery phase.
  All other nodes that already joined the cluster wait for the seed node to finish data loading and initial pruning.
  The discovery phase can not start until the seed node removed all constant columns and reduced the order equivalent columns.
  Therefore, the seed node broadcasts the reduced column set to all joined nodes once it finished pruning them.
  Our algorithm requires all nodes to have access to the whole dataset, because we do not partition the candidates and every node can check every candidate.
  This means that nodes load the dataset from their neighbors using data streaming, where the seed node is the data origin.

  Every node needs the dataset, the reduced column set, and some \gls{ocd} candidates to start the discovery.
  Later joining nodes, therefore, ask their direct neighbors in the ring for the dataset and the reduced column set.
  The distribution of \gls{ocd} candidates is implemented using a work stealing protocol, which we describe in \cref{protocol:workStealing}.

\subsection{\dodo{} node architecture}\label{sec:node-architecture}

  Every node in the cluster has the same internal architecture, because the nodes form a peer-to-peer cluster, where all nodes are equal.
  Every node can become the seed node that performs the initialization steps at the beginning of the algorithm.
  The node architecture is shown in \cref{fig:dodo-architecture} on the right as an example for node 2.
  Each node employs its own actor system running actors of seven different actor types.

  \begin{description}
  \item[Master]
    For each node we use a master-worker pattern to utilize the multi-processing and multi-threading capabilities of the node.
    The Master actor is the node-local coordinator responsible for holding the processing state and communicating with the other nodes.
    It uses a data holder actor and a state replicator actor to outsource some of the management logic.
    Both those actor types are explained later on.
    The Master actor's state consists of a \gls{ocd} candidate queue and a pending work queue.
    We use a pull-based approach for the distribution of tasks to Worker actors on a node.
    An idle Worker asks the Master for the next work packet (a batch of \gls{ocd} candidates) and the Master sends the packet to the Worker actor and moves the candidates to the pending work queue.
    After receiving the results from the Worker the Master removes the candidates from the pending work queue.
    This means that the Master does not have to monitor the state of every single Worker.
    The Master also implements the work stealing protocol (see \cref{protocol:workStealing}) to balance the work across the nodes in the cluster and it initiates the node shutdown when their is no more work left and all \glspl{od} have been found (see \cref{protocol:downing}).

  \item[Worker]
    A node can have an arbitrary number of Worker actors.
    We propose to use $n - 1$ Workers, where $n$ is the number of available threads on the node.
    This ensures that one thread is still available even if the Workers are blocking the threads, which should not occur.
    The Workers perform the actual work of our algorithm.
    They check \gls{ocd} and \gls{od} candidates and derive new ones from the found \glspl{ocd}.
    The new candidates are pruned and then sent back to the Master.
    This work consumes most of the processing resources and is therefore spread across multiple Worker actors on each node.
    The Workers send all found \glspl{ocd} and \glspl{od} to the local Result Collector actor, which records them in a persistent file.

  \item[Result Collector]
    The Result Collector actor receives the \glspl{od} and \glspl{ocd} from the local Workers.
    It collects and counts these results and writes them to a file, so they can be recovered even if the node fails unexpectedly.

  \item[Data Holder]
    The Data Holder actor is responsible for loading the dataset and for storing the dataset in heap.
    If we provide a file path to a dataset to the node during startup, the Data Holder will load and parse the dataset from disk.
    It also performs type inference to ensure the correct ordering relation for dates, numbers and text.
    If no file path is available, the Data Holder asks the node's neighbors on the ring (see Cluster Listener actor) to stream the dataset to it.
    Once the dataset is loaded in memory, the Data Holder makes the reference available to the Master and the Worker actors.
    From this point on it is able to stream the dataset to other nodes as well.

  \item[State Replicator]
    The State Replicator actor is a utility actor for the Master actor.
    It holds the state of its two neighboring nodes and shares the state of its own local Master actor with them.
    This enables us to recover work from unexpectedly failed nodes and is explained in more detail in  \cref{protocol:stateReplication}.

  \item[Cluster Listener]
    Each node in the \dodo{} cluster has a position on a conceptual node-ring.
    The position is determined based on the node's network address consisting of hostname and port information.
    Leaving and joining nodes change the arrangement of the nodes on the ring.
    The Cluster Listener actor is responsible for creating a representation of the ring structure and for listening on cluster events introducing or removing nodes.
    It determines the position of the local node on the ring and shares the neighboring node's address information with the other local actors.
    Whenever the neighbors of the local node change, the updated neighbors are sent to the State Replicator to change the target for state updates.
    In contrast, the Data Holder only receives information about the neighboring nodes, when it specifically asks for them, because it only needs the information when requesting the dataset from another node.

  \item[Reaper]
    The Reaper actor watches all other actors and cleanly shuts down the local actor system once all of them are terminated.
  \end{description}

\subsection{Communication protocols}\label{sec:protocols}

  This section introduces the three core communication protocols used by \dodo{}.
  They allow \dodo{} to dynamically scale to a different number of nodes in a cluster and to be fault-tolerant in the case of message loss and node failures.
  \dodo{} is able to rebalance work across the cluster.
  This allows us to dynamically add more nodes to an already running cluster.
  This is implemented by the work stealing protocol introduced in the next section (\cref{protocol:workStealing}).
  \Cref{protocol:downing} then describes the downing protocol, which ensures that all nodes only shut down if there is no more work available in the whole cluster.
  In \cref{protocol:stateReplication}, we present our state replication protocol that synchronizes the nodes' states to their cluster neighbors to prevent loss of candidates.

\subsubsection{Work stealing protocol}\label{protocol:workStealing}

  % Possible picture (sequence diagram): https://sequencediagram.org/index.html#initialData=C4S2BsFMAIHUHsBOBraBlYkCG4QDsBzaABUXmHgGN5wAoWgFQAsRIAzaPeAE0gFoAfF17QATAC4A4pGAIU4eFm6MW7Tj35CN0AMxSZc5AqUrWHYZovQALPtlIji5VdGDmZ9b3GHj3ABQAjAAMAJS0VjpuquYa3g6+fgBsYVbWUR4WcfJOfgAcYe5qFulFsQwgALaQ8ACuwKalvIIu4hjY4IZ+1gXRnpbatm04naIp2q4ChTFeGDSQeJ3W0JRYeNwg3FiYAM5jImmTvZmzUAsOfqLLq+ubOz0ZGs3j4gCClMgn84YN0-37r+9PmcUEA
  When a node is out of work, either because it just joined the cluster or because all the candidates it checked got pruned and no new candidates were generated, it tries to take over some of the work of the other nodes in the cluster.
  We call this process work stealing.
  It ensures that no node is idle while the others are still checking candidates and it balances the workload over the cluster.
  The workload of a node is defined by the number of candidates waiting to be processed in its candidate queue.
  Ideally every node would have processed nearly the same number of candidates at the time the algorithm ends.

  The work stealing protocol consists of three phases: preparation, stealing, and acknowledgment.
  It is initiated when a node's candidate queue is empty, even if some of its workers are still processing candidates and might return new ones soon.
  Starting work stealing this early reduces idle times.
  The node with the empty candidate queue (the thief node) starts the preparation phase by asking all other nodes for their current workload.
  Because some nodes might be very busy, it only waits for a specific duration to receive the results.
  Only the nodes from which the thief received answers are considered as potential victims.
  The thief node calculates the average workload of the potential victim nodes and itself.
  This is the ideal workload for every node.
  To improve the work distribution in the cluster, the thief only requests candidates from nodes that have a workload above average and only so many candidates that its own workload does not exceed the average.
  It then proceeds to the stealing phase.

  In the stealing phase the thief sends out the requests to steal work from the other nodes.
  Those requests are directed to the selected victims and contain the amount of requested candidates.
  The victim node sends back the requested number of candidates to the thief, but at most half of the candidates in its candidate queue.
  This ensures that the victim node is not running out of work directly after sending out its candidates to another node, which would lead to the candidates being send back and forth between two or more nodes.
  The number of candidates left in the victim's queue might be less than initially computed, because it could have processed a lot of them in the meantime.
  To prevent data loss, the victim is not directly deleting the stolen candidates from its queue, but it is moving them into another queue, awaiting the acknowledgment of the thief.

  In the acknowledgment phase, the thief node concurrently receives the candidates from the victims and adds them to its own pending queue.
  It sends the acknowledgments to the victims, so that they can delete the stolen candidates.
  To ensure that the sent candidates arrive at the thief node and will get processed, the victim uses Akka's actor monitoring to get notified if the thief node dies.
  In the case that the thief fails before it could acknowledge the receipt of the candidates, the victim will recover the to-be-stolen candidates and add them back to its own candidate queue.

\subsubsection{Downing protocol}\label{protocol:downing}

  When all \glspl{od} have been found and there are no more candidates to check, the system should shut itself down cleanly.
  \dodo{} is distributed across different nodes that act relatively autonomous.
  This means they have to communicate with each other to figure out if all of the nodes are out of work.
  The downing protocol defines the communication required to achieve a complete and clean shutdown of the cluster ensuring that all \gls{ocd} candidates have been processed.

  A node starts the downing protocol, when it has no more candidates in its candidate queue, all local Worker actors have finished processing, and an attempt to get more work using work stealing was unsuccessful.
  We have to make sure that no more Workers are processing candidates, because each candidate that is being processed could generate new candidates for the candidate queue.
  If the three mentioned criteria a fulfilled, a \dodo{} node changes into a downing state, where it is idle and waiting for shutdown.
  It must now ensure that all other cluster nodes also have no more work left.
  If another node still holds unprocessed candidates or is still in the process of creating new candidates, these candidates could be redistributed in the cluster using work stealing.
  This means that the idle node can contribute its resources instead of shutting itself down.
  Therefore, the node asks all cluster members if they are ready for shutdown.
  It waits for a response from every other node in the cluster, also being aware of nodes leaving the cluster and subsequently not awaiting their response anymore.
  If any of the other nodes responds with a message indicating that they are still holding or processing candidates, the node leaves the downing state and starts the work stealing protocol again.
  If all nodes have either left the cluster or responded that they have no more work, the node shuts itself down.
  This process is the same for all other nodes in the cluster and eventually all nodes will shut down.

\subsubsection{State replication protocol}\label{protocol:stateReplication}

  The state replication protocol ensures that a \dodo{} cluster can tolerate complete node failures without losing work.
  Every node regularly replicates its state to its left and right neighbor in the cluster ring.
  Only if three neighboring nodes fail simultaneously would \dodo{} lose the unprocessed candidates of one node.
  In the case of this rare failure scenario, the whole \dodo{} cluster would need to be restarted to ensure complete results.

  The basis of the state replication protocol is the node ring, because the node's position on the ring determines the state replication targets.
  The ring structure is computed by the Cluster Listener actors based on the nodes' network addresses.
  It is implemented as double linked list, where the last node also holds a reference to the first node and the other way around.
  Every node replicates its state to its predecessor and successor in this list.
  The State Replication actors are responsible for sending their nodes' state to its neighbors in a regular interval.
  They are also the receiving endpoint and storage for the incoming state messages from the other nodes.
  The state replication interval can be configured by the user of the \dodo{} algorithm.

  When it is time to replicate the state the State Replicator asks the Master for its current state of the candidate queue and the pending work queue.
  It then takes the neighbor's addresses, received from the local Cluster Listener actor, and sends out the state and an increasing version number to them.
  The receiving nodes compare the incoming version number with their local state's version.
  If the new state version is higher, they save the new state and forget the old one.
  If it is not, they discard the incoming message, because their existing state replica is more recent.
  We do not use acknowledgments for state transmissions, because the regular replication interval ensures that the replication is tried again in the case of message loss and we want to reduce the stress on the network.

  There is a special case, when a state replication is triggered outside of the regular interval.
  When a new node joins the cluster, the Cluster Listener updates and reorders its list of all the nodes in the cluster.
  It then notifies the State Replicator actor about the changed neighbors.
  If the node's neighbors have changed, the State Replicator sends its own state to its new neighbor right away and marks the state of the node that is no longer its neighbor for deletion.
  It will be overwritten once the State Replicator received the state of its new neighbor.
  This ensures that the new node arrangement is quickly reflected in the state replication status and keeps the time, where a node only has one other state replica small.

  In the case of a node failure or when a node leaves the cluster, the cluster must recover the work the leaving node did not finish.
  Both neighbors of the leaving node are alerted about the event by their local Cluster Listener.
  The Cluster Listener automatically rearranges the nodes in the ring and informs the State Replicator about the left node and its new neighbor.
  This new neighbor was the leaving nodes other neighbor.
  This means that the new neighbor also holds a replica of the left node's state.
  To determine which of the two nodes has the most up to date state of the leaving node, they exchange the version numbers of their state replicas.
  The node with the higher version number adds the leaving nodes state to its own candidate queue to ensure that all candidates get processed.
  The node with the lower version number deletes its local copy of the leaving node's state.
  The two nodes then share their updated state with each other to reach a three-fold state replication for all nodes again.

  Some time might have elapsed between the last state replication and the node failure.
  This means that in the meantime the failing node generated candidates that are not reflected in the state replicas.
  The new candidates are no problem, because they can be recomputed from the existing candidates in the state replica.
  The results were made persistent on the local disk of the failed node and can be recovered.
  However, as some candidates are processed by the failed node and the node that recovered the state, \dodo{} will produce duplicate results in the presence of node failures.
