% !TeX root = ../paper.tex
% !TeX encoding = UTF-8
% !TeX spellcheck = en_US

\section{Distributed discovery of \glspl{od}}\label{sec:approach}

  We now present our approach to \gls{od} discovery, called \dodo{}.
  First, we explain how \ocddiscover{}~\cite{consonni} traverses the candidate space to find minimal \glspl{ocd} and \glspl{od} in \cref{sec:ocddiscover}.
  This is the algorithmic foundation of our approach, which we slightly adopt to be able to distribute the discovery across several nodes in a cluster (see \cref{sec:dodo}).
  \Cref{sec:architecture} then describes \dodo{}'s architecture and \cref{sec:protocols} the communication protocols used to make a \dodo{} cluster fault-tolerant and elastic.
 
\subsection{The \ocddiscover{} algorithm}\label{sec:ocddiscover}

  The \ocddiscover{} algorithm creates the search space to find \glspl{od} over \glspl{ocd}~\cite{consonni}.
  This reduces the number of candidates that the algorithm must check, because \glspl{ocd} are symmetrical.
  \Citeauthor{consonni} prove that if a \gls{od} holds, than a functional dependency and a \gls{ocd} hold as well.
  Based on this theorem, they then use a breadth-first search strategy to identify \gls{ocd} relations in the dataset to discover minimal dependencies before longer ones.

  The \ocddiscover{} algorithm consists of two phases.
  In the first phase, \ocddiscover{} performs an initial pruning step that removes constant columns and reduces order equivalent columns of the original column set.
  The constant columns and order equivalent columns are part of the output.
  They would generate a huge amount of \glspl{od} and those \glspl{od} can easily reconstructed from the result later on.

  In the second phase, the actual \gls{od} discovery takes place.
  \ocddiscover{} generates \gls{ocd} candidates from the remaining columns in levels, one after the other.
  For each level the algorithm checks if the \gls{ocd} candidates hold.
  If a candidate holds, the candidate is further checked for being order dependent, the results are emitted, and child \gls{ocd} candidates are generated.
  This step includes further pruning rules~\cite{consonni}.
  If the \gls{ocd} candidate does not hold, no new candidates starting from it are generated.
  All newly generated candidates are then put into a list for the next level.

  \Citeauthor{consonni} proved in their paper, that they would be able to find all minimal \glspl{od}.
  However, as \citeauthor{szlichta:errata} showed in their Errata Note, \citeauthor{consonni} made a mistake in one of their proofs and this method of building the search space does not create minimal \glspl{od} with repeated prefixes~\cite{szlichta:errata}.

\subsection{The \dodo{} algorithm}\label{sec:dodo}

  We use \citeauthor{consonni}'s work as the basis of our discovery algorithm.
  Conceptually, \dodo{} works the same as \ocddiscover{}.
  This means that we also perform a breadth-first search in a \gls{ocd} candidate tree and our algorithm also consists of an initial pruning step followed by the actual search step.
  However, our implementation of the algorithm differs.

  Instead of generating our candidates level-wise, we use a task-based approach with a single task queue.
  We initiate the task queue with the initial \gls{ocd} candidates comparable to the first level generation by \citeauthor{consonni}.
  Each task's input is the \gls{ocd} candidate.
  Its outputs are the results from checking the candidate and a set of new tasks that can be empty.
  The results are emitted as output and the new tasks (child candidates) are added to the task queue.
  This is possible, because \gls{ocd} candidate checking and the generation of new candidates is independent from the other candidates~\cite{consonni}.
  This setup allows us to parallelize the processing, because the tasks in the task queue can be processed independently and concurrently.
  To distribute our algorithm, we just spread the tasks, ideally evenly, across our cluster.

\subsection{Implementation of the \dodo{} algorithm}\label{sec:architecture}

  We implement the \dodo{} algorithm using Akka~\cite{akka}, Akka Clustering~\cite{akka:clustering} and the Scala programming language~\cite{scala}.
  Akka is a toolkit for building distributed message-driven applications using the actor programming model that was first introduced in Orleans~\cite{bernstein:orleans}.
  It provides tools for concurrency, distribution, and elasticity.

  The \dodo{} algorithm is designed as a peer-to-peer cluster.
  All nodes in the cluster are equal and employ the same internal architecture.
  The nodes are arranged on a ring, so that every node has two neighbors.
  Based on this cluster layout, we define communication protocols (see \cref{sec:protocols}) to balance the workload, to recover from node failures, and to allow dynamic cluster sizes.
  Each node runs its own actor system with the complete set of \dodo{} actors (\cref{sec:node-architecture} describes them in more detail) and works on the checking of \glspl{ocd} and the generation of new \gls{ocd} candidates.
  \Cref{fig:dodo-architecture} shows the cluster architecture and the internal architecture of the nodes' actor systems exemplarily by node two.

  \begin{figure}
    \centering
    \input{pictures/tikz/dodo-architecture}
    \caption{DODO architecture}
    \label{fig:dodo-architecture}
  \end{figure}

  The execution of the \dodo{} algorithm in the cluster is initiated by a seed node.
  The seed node plays a special role in our cluster and it is the only exception to the peer-to-peer approach.
  It is started before all other nodes and has the following unique tasks:

  \begin{itemize}
    \item The seed node is the initial contact point for all nodes that want to join the cluster.
    \item It always loads the dataset from disk into memory.
    \item It performs the initial pruning and generates the first \gls{ocd} candidates.
  \end{itemize}

  The seed node is the first node in the cluster and may be the only one in the cluster for some time.
  If the seed node fails during this first phase, the whole cluster shuts down and must be restarted.
  We do not implement resilience for this first phase.
  This seemed to be a reasonable constraint, though, because the first phase only takes a few seconds.

  After the seed node started up, it immediately starts with the discovery phase.
  All other nodes that already joined the cluster wait for the seed node to finish data loading and initial pruning.
  The discovery phase can not start until the seed node removed all constant columns and reduced the order equivalent columns.
  Therefore, the seed node broadcasts the reduced column set to all joined nodes once it finished pruning them.
  Our algorithm requires all nodes to have access to the whole dataset, because we do not partition the candidates and every node can check every candidate.
  This means that nodes load the dataset from their neighbors using data streaming, where the seed node is the data origin.

  Every node needs the dataset, the reduced column set, and some \gls{ocd} candidates to start the discovery.
  Later joining nodes, therefore, ask their direct neighbors in the ring for the dataset and the reduced column set.
  The distribution of \gls{ocd} candidates is implemented using a work stealing protocol, which we describe in \cref{protocol:workStealing}.

\subsection{\dodo{} node architecture}\label{sec:node-architecture}
  Every node in the cluster has the same internal architecture, because the nodes form a peer-to-peer cluster, where all nodes are equal.
  Every node can become the seed node that performs the initialization steps at the beginning of the algorithm.
  The node architecture is shown in \cref{fig:dodo-architecture} on the right as an example for node 2.
  Each node employs its own actor system running actors of seven different actor types.

  \begin{description}
  \item[Master]
    For each node we use a master-worker pattern to utilize the multi-processing and multi-threading capabilities of the node.
    The Master actor is the node-local coordinator responsible for holding the processing state and communicating with the other nodes.
    It uses a data holder actor and a state replicator actor to outsource some of the management logic.
    Both those actor types are explained later on.
    The Master actor's state consists of a \gls{ocd} candidate queue and a pending work queue.
    We use a pull-based approach for the distribution of tasks to Worker actors on a node.
    An idle Worker asks the Master for the next work packet (a batch of \gls{ocd} candidates) and the Master sends the packet to the Worker actor and moves the candidates to the pending work queue.
    After receiving the results from the Worker the Master removes the candidates from the pending work queue.
    This means that the Master does not have to monitor the state of every single Worker.
    The Master also implements the work stealing protocol (see \cref{protocol:workStealing}) to balance the work across the nodes in the cluster and it initiates the node shutdown when their is no more work left and all \glspl{od} have been found (see \cref{protocol:downing}).

  \item[Worker]
    A node can have an arbitrary number of Worker actors.
    We propose to use $n - 1$ Workers, where $n$ is the number of available threads on the node.
    This ensures that one thread is still available even if the Workers are blocking the threads, which should not occur.
    The Workers perform the actual work of our algorithm.
    They check \gls{ocd} and \gls{od} candidates and derive new ones from the found \glspl{ocd}.
    The new candidates are sent back to the Master.
    This work consumes most of the processing resources and is therefore spread across multiple Worker actors on each node.
    The Workers send all found \glspl{ocd} and \glspl{od} to the local Result Collector actor, which records them in a persistent file.

  \item[Result Collector]
    The Result Collector actor receives the \glspl{od} and \glspl{ocd} from the local Workers.
    It collects and counts these results and writes them to a file, so they can be recovered even if the node fails unexpectedly.

  \item[Data Holder]
    The Data Holder actor is responsible for loading the dataset and for storing the dataset in heap.
    If we provide a file path to a dataset to the node during startup, the Data Holder will load and parse the dataset from disk.
    It also performs type inference to ensure the correct ordering relation for dates, numbers and text.
    If no file path is available, the Data Holder asks the node's neighbors on the ring (see Cluster Listener actor) to stream the dataset to it.
    Once the dataset is loaded in memory, the Data Holder makes the reference available to the Master and the Worker actors.
    From this point on it is able to stream the dataset to other nodes as well.

  \item[State Replicator]
    The State Replicator actor is a utility actor for the Master actor.
    It holds the state of its two neighboring nodes and shares the state of its own local Master actor with them.
    This enables us to recover work from unexpectedly failed nodes and is explained in more detail in  \cref{protocol:stateReplication}.

  \item[Cluster Listener]
    Each node in the \dodo{} cluster has a position on a conceptual node-ring.
    The position is determined based on the node's network address consisting of hostname and port information.
    Leaving and joining nodes change the arrangement of the nodes on the ring.
    The Cluster Listener actor is responsible for creating a representation of the ring structure and for listening on cluster events introducing or removing nodes.
    It determines the position of the local node on the ring and shares the neighboring node's address information with the other local actors.
    Whenever the neighbors of the local node change, the updated neighbors are sent to the State Replicator to change the target for state updates.
    In contrast, the Data Holder only receives information about the neighboring nodes, when it specifically asks for them, because it only needs the information when requesting the dataset from another node.

  \item[Reaper]
    The Reaper actor watches all other actors and cleanly shuts down the local actor system once all of them are terminated.
  \end{description}

\subsection{Communication protocols}\label{sec:protocols}
% Questions to be answered for each one:
% What is its purpose? 
% When is the protocol started and what is the desired outcome? 
% Who is communicating? 
% What Messages are being used?
% What cases need to be covered? (Early outs etc)

\subsubsection{Work stealing protocol}\label{protocol:workStealing}
% Possible picture (sequence diagram): https://sequencediagram.org/index.html#initialData=C4S2BsFMAIHUHsBOBraBlYkCG4QDsBzaABUXmHgGN5wAoWgFQAsRIAzaPeAE0gFoAfF17QATAC4A4pGAIU4eFm6MW7Tj35CN0AMxSZc5AqUrWHYZovQALPtlIji5VdGDmZ9b3GHj3ABQAjAAMAJS0VjpuquYa3g6+fgBsYVbWUR4WcfJOfgAcYe5qFulFsQwgALaQ8ACuwKalvIIu4hjY4IZ+1gXRnpbatm04naIp2q4ChTFeGDSQeJ3W0JRYeNwg3FiYAM5jImmTvZmzUAsOfqLLq+ubOz0ZGs3j4gCClMgn84YN0-37r+9PmcUEA
When a node is out of work, either because it just joined the cluster or because all the candidates it checked got pruned and did not generate any new candidates to check, it tries to take over some of the work of the other nodes. 
This process is called \emph{Work Stealing}.
We use it to ensure that no node is idle while the others are still checking candidates and to balance the workload over the cluster. 
The workload of a node is defined by the number of candidates waiting to be processed in its queue. 
In the desired outcome to add to its own queue of the \emph{Work Stealing Protocol}, each node ends up with a similar workload. 
To achieve this goal the \emph{Master Actors} of the different nodes communicate their workloads with each other.\\
The \emph{Work Stealing Protocol} is initiated when a node's \emph{Candidate Queue} is empty, even if some of its workers are still processing candidates and might return new ones soon.
This node (the \emph{Thief node}) sends a message to all other nodes, asking for the current size of their \emph{Candidate Queues}.
It also sets a timeout after which it processes the answers of the other nodes. 
During this processing step it calculates the average \emph{Candidate Queue's} length of all the nodes that answered and itself.
To improve the balancing of workloads over the cluster, the \emph{Thief node} only takes candidates from nodes that have a \emph{Candidate Queue} of above average length and only takes so many candidates that its own \emph{Candidate Queue's} length does not exceed the average. 
% Explain in more detail / with pseudocode?
To get the candidates from another node's \emph{Candidate Queue}, the \emph{Thief node} sends a message with the amount of candidates it wants to take to the node it wants to take them from.
This node, the \emph{Victim node}, then moves the asked for candidates from its \emph{Candidate Queue} into its \emph{Pending Queue} and sends them to the \emph{Thief node}.
However, since the \emph{Victim node's} queue might have changed since it first sent its length to the \emph{Thief node}, the \emph{Victim node} sends back at most half of the candidates in its queue.
Once the \emph{Thief node} receives the candidates, it adds them to its own queue and sends a message acknowledging the receipt to the \emph{Victim node}, which then deletes the candidates from its \emph{Pending queue}. 
To ensure the send candidates arrive and will get processed, the \emph{Victim node} watches the \emph{Thief node}.
In the case that the \emph{Thief node} fails before it could acknowledge the receipt of the candidates, the \emph{Victim node} moves them back to its own \emph{Candidate queue} from its \emph{Pending queue}.
 
\subsubsection{Downing protocol}\label{protocol:downing}
When all \glspl{od} have been found and there are no more candidates to check, the system should shut itself down.
A node starts the \emph{Downing Protocol}, when it has no more candidates in its \emph{Candidate Queue} and \emph{Pending Queue} and an attempt to get more work using \emph{Work Stealing} was unsuccessful.
Checking the \emph{Pending Queue} is important because candidates currently being processed could generate new candidates and therefore new work.\\
To ensure that there are no more candidates to be processed and no more candidates being generated in the whole cluster, the node has to ask every other node, whether they are also out of candidates.
If another node still holds unprocessed candidates or is still in the process of creating new candidates, these could be redistributed over the cluster using \emph{Work Stealing} so the node can continue to work instead of shutting itself down.
The node waits for a response from every other node in the cluster, also being aware of nodes leaving the cluster and subsequently not awaiting their response anymore.\\
If any of the other nodes respond with a message saying that they are still holding or processing candidates, the node switches from the \emph{Downing} to the \emph{Work Stealing Protocol}.
If all nodes have either left the cluster or responded that they have no more work, the node shuts itself down.

\subsubsection{State replication protocol}\label{protocol:stateReplication}
To ensure any of the nodes of the cluster can fail without any work getting lost, every node regularly replicates its state to two other nodes.
Because of this, three specific nodes would have to fail simultaneously to permanently lose any unprocessed candidates. 
In this case, everything would need to be restarted to ensure complete results. \\
Which nodes the state is sent to is decided by their addresses.
All nodes in a cluster are ordered by their addresses and every node replicates its state to both its neighbors in this ordering.
The first and last node in this ordering are also each others neighbors.\\
Every node has a \emph{State Replication Actor} responsible for regularly sending the node's state to its neighbors and processing these neighbor's states when they are sent.
It gets the information of who its neighbors are from the \emph{Cluster Listener Actor}. \\
In regular intervals, the \emph{State Replicator} asks the \emph{Master Actor} for its current state.
The state is a combination of its \emph{Candidate Queue} and \emph{Pending Queue}.
On receiving the \emph{Master's} current state, the \emph{State Replicator} sends to both its neighbors with a version number that is continually increased.\\
When a \emph{State Replicator} receives the state of one of its neighbors, it checks whether the version number in the new message is higher than the version number of the last state it received from that actor.
If this is the case, it saves the new state and version number.
If not, is discards the new message, because it already has a more up to date state for that actor.

\paragraph{A node joins the cluster}
When a new node joins the cluster, the \emph{Cluster Listener} updates its ordering of all the nodes in the cluster. 
It then sends the \emph{State Replicator} the updated neighbor information.
If the nodes neighbor has changed, the \emph{State Replicator} removes the state of the node that is no longer its neighbor and sends its own state to its new neighbor.

\paragraph{A node leaves the cluster}
When a node leaves the cluster, its two neighbors have to decide which of them will take on the work the leaving node did not finish.
They are alerted to their neighbor's leaving by the \emph{Cluster Listener} who also immediately tells them, who their new neighbor is.
This new neighbor was the leaving nodes other neighbor.
To determine which of the two has the most up to date state of the leaving node, they share the version number of the leaving node's state. 
The node with the higher version number adds the leaving nodes state to its own \emph{Candidate Queue} to ensure all candidates get processed. 
The node with the lower version number deletes the state of the leaving node.
The two nodes then share their state with each other. 