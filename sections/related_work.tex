% !TeX root = ../paper.tex
% !TeX encoding = UTF-8
% !TeX spellcheck = en_US

\section{Related Work}\label{sec:related_work}

In comparison to the related field of functional dependencies, literature on \glspl{od} is comparatively rare.
The idea of considering the ordering of attributes in a relation as a kind of dependency was first introduced in 1982 by \citeauthor{ginsburg}~\cite{ginsburg}.
Their work formalizes the so-called \textit{point-wise ordering} with a complete set of inference rules and shows that the problem of inference in their formalism is co-NP-complete~\cite{ginsburg}.
\citeauthor{ginsburg}'s definition of \textit{point-wise ordering} specifies that a set of attributes in a relation orders another set of attributes.

In 2012, \citeauthor{szlichta:fundamentals}~\cite{szlichta:fundamentals} introduced a definition for \glspl{od}, which considers lists of attributes instead of sets of attributes.
This leads to a lexicographical ordering of tuples as generated by the \texttt{ORDER BY} operator in SQL.
The definition of \glspl{od} by \citeauthor{szlichta:fundamentals} was used throughout the following research in this area~\cite{consonni, langer, szlichta:discovery} and is also the basis of this work.

The problem of efficient discovery of \glspl{od} in existing datasets using \citeauthor{szlichta:fundamentals}'s definition was first approached by \citeauthor{langer}~\cite{langer}.
Their algorithm is called \order{} and first computes all potential \gls{od} candidates and then traverses the candidate lattice in a bottom-up manner employing pruning rules.
\order{} has a factorial worst-case complexity over the number of attributes in the relation.
Unfortunately, the aggressive pruning rules of \order{} affect the completeness of their results~\cite{szlichta:discovery}.

\citeauthor{szlichta:discovery} present another approach to \gls{od} discovery called \fastod{}.
It is complete and faster than \order{}.
\fastod{} uses a polynomial mapping of list-based \glspl{od} to a set-based canonical form, which reduces the algorithm's worst-case complexity to $O(2^{\left|n\right|})$, in the number of attributes $n$.

Most recently, \citeauthor{consonni}~\cite{consonni} presented a third approach on \gls{od} discovery using the concept of \glspl{ocd}, called \ocddiscover{}.
It has a factorial worst-case runtime, but \citeauthor{consonni} showed that it can outperform \fastod{} on some datasets.
\ocddiscover{} is capable of running multi-threaded, which makes it easier to adapt the algorithm to a distributed system.
This was the state of published research when we started on our project, which is why we based our own algorithm on \ocddiscover{}.
Since then, \citeauthor{szlichta:errata}~\cite{szlichta:errata} have published an Errata Note demonstrating an error in \citeauthor{consonni}'s proof of minimality, which renders the results of \ocddiscover{} incomplete.
We still base our approach on \ocddiscover{}, since the goal of our work is the distribution of an already existing algorithm with a focus on reliability and scalability.
